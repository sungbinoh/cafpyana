{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wiener SBND Unfolding for numu CC 1p0pi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib as mpl\n",
    "from os import path\n",
    "import sys\n",
    "import uproot\n",
    "from tqdm import tqdm\n",
    "\n",
    "# local imports\n",
    "from variable_configs import *\n",
    "\n",
    "sys.path.append('/exp/sbnd/app/users/munjung/xsec/wienersvd/cafpyana')\n",
    "from analysis_village.unfolding.wienersvd import *\n",
    "from analysis_village.unfolding.unfolding_inputs import *\n",
    "from analysis_village.numucc1p0pi.selection_definitions import *\n",
    "from pyanalib.split_df_helpers import *\n",
    "from makedf.mcstat import *\n",
    "from makedf.geniesyst import regen_systematics_sbnd_multisigma, regen_systematics_sbnd_morph\n",
    "from makedf.constants import *\n",
    "\n",
    "plt.style.use(\"presentation.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig = False\n",
    "save_fig_dir = \"/exp/sbnd/data/users/munjung/plots/wiener_svd/1mu1p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = mpl.cm.viridis\n",
    "norm = mpl.colors.Normalize(vmin=0.0, vmax=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- MC study\n",
    "mc_file = \"/exp/sbnd/data/users/munjung/xsec/2025B/MC_test.df\"\n",
    "mc_split_df = pd.read_hdf(mc_file, key=\"split\")\n",
    "mc_n_split = get_n_split(mc_file)\n",
    "print(\"mc_n_split: %d\" %(mc_n_split))\n",
    "print_keys(mc_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max_concat = 2\n",
    "\n",
    "mc_keys2load = ['evt', 'hdr', 'mcnuwgtslim']\n",
    "mc_dfs = load_dfs(mc_file, mc_keys2load, n_max_concat=n_max_concat)\n",
    "\n",
    "mc_evt_df = mc_dfs['evt']\n",
    "mc_hdr_df = mc_dfs['hdr']\n",
    "mc_nu_df = mc_dfs['mcnuwgtslim']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make MCstat uncertainty universes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_evt_df, MCstat_univ_events = mcstat(mc_evt_df, mc_hdr_df, n_universes=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## total pot\n",
    "mc_tot_pot = mc_hdr_df['pot'].sum()\n",
    "print(\"mc_tot_pot: %.3e\" %(mc_tot_pot))\n",
    "\n",
    "target_pot = 1e20\n",
    "mc_pot_scale = target_pot / mc_tot_pot\n",
    "print(\"mc_pot_scale: %.3e\" %(mc_pot_scale))\n",
    "mc_pot_scale = 1.\n",
    "\n",
    "mc_evt_df[\"pot_weight\"] = mc_pot_scale * np.ones(len(mc_evt_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: z-dependence?\n",
    "# flux file, units: /m^2/10^6 POT \n",
    "# 50 MeV bins\n",
    "fluxfile = \"/exp/sbnd/data/users/munjung/flux/sbnd_original_flux.root\"\n",
    "flux = uproot.open(fluxfile)\n",
    "print(flux.keys())\n",
    "\n",
    "# numu flux\n",
    "numu_flux = flux[\"flux_sbnd_numu\"].to_numpy()\n",
    "bin_edges = numu_flux[1]\n",
    "flux_vals = numu_flux[0]\n",
    "\n",
    "plt.hist(bin_edges[:-1], bins=bin_edges, weights=flux_vals, histtype=\"step\")\n",
    "plt.xlabel(\"E [GeV]\")\n",
    "plt.ylabel(\"Flux [/m$^{2}$/10$^{6}$ POT]\")\n",
    "plt.title(\"SBND $\\\\nu_\\\\mu$ Flux\")\n",
    "plt.show()\n",
    "\n",
    "# get integrated flux\n",
    "integrated_flux = flux_vals.sum()\n",
    "integrated_flux /= 1e4 # to cm2\n",
    "INTEGRATED_FLUX = integrated_flux * mc_tot_pot / 1e6 # POT\n",
    "print(\"Integrated flux: %.3e\" % INTEGRATED_FLUX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_SBND = 380 * 380 * 440 # cm3, the active volume of the detector \n",
    "NTARGETS = RHO * V_SBND * N_A / M_AR\n",
    "print(\"# of targets: \", NTARGETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to 1 for event rates\n",
    "XSEC_UNIT = 1 / (INTEGRATED_FLUX * NTARGETS)\n",
    "\n",
    "# XSEC_UNIT = 1\n",
    "print(\"xsec unit: \", XSEC_UNIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up utils and selections according to target channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional selection?\n",
    "mc_evt_df = mc_evt_df[InFV(mc_evt_df.slc.vertex,)]\n",
    "\n",
    "# neutrino cuts\n",
    "mc_evt_df = mc_evt_df[mc_evt_df.slc.nu_score > 0.5]\n",
    "\n",
    "# require both muon and proton to be present\n",
    "mask = (~np.isnan(mc_evt_df.mu.pfp.trk.P.p_muon)) & (~np.isnan(mc_evt_df.p.pfp.trk.P.p_proton))\n",
    "mc_evt_df = mc_evt_df[mask]\n",
    "\n",
    "# muon length cut\n",
    "mc_evt_df = mc_evt_df[mc_evt_df.mu.pfp.trk.len > 50]\n",
    "\n",
    "# containment cut\n",
    "mc_evt_df = mc_evt_df[mc_evt_df.mu.pfp.trk.is_contained == True]\n",
    "mc_evt_df = mc_evt_df[mc_evt_df.p.pfp.trk.is_contained == True]\n",
    "\n",
    "# mu chi2 cut \n",
    "mc_evt_df = mc_evt_df[(mc_evt_df.mu.pfp.trk.chi2pid.I2.chi2_muon > 0) & (mc_evt_df.mu.pfp.trk.chi2pid.I2.chi2_muon < 25) & (mc_evt_df.mu.pfp.trk.chi2pid.I2.chi2_proton > 100)]\n",
    "\n",
    "# protons chi2 cut\n",
    "mc_evt_df = mc_evt_df[(mc_evt_df.p.pfp.trk.chi2pid.I2.chi2_proton > 0) & (mc_evt_df.p.pfp.trk.chi2pid.I2.chi2_proton < 90)]\n",
    "\n",
    "# 1p0pi\n",
    "twoprong_cut = (np.isnan(mc_evt_df.other_shw_length) & np.isnan(mc_evt_df.other_trk_length))\n",
    "mc_evt_df = mc_evt_df[twoprong_cut]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make it work with the get_covariance function...\n",
    "\n",
    "# Turn GENIE multisigma into multisims with 2 universes\n",
    "for knob in regen_systematics_sbnd_multisigma:\n",
    "    mc_evt_df[(knob, \"univ_0\", \"\", \"\", \"\", \"\", \"\", \"\")] = mc_evt_df[knob].ps1\n",
    "    mc_evt_df[(knob, \"univ_1\", \"\", \"\", \"\", \"\", \"\", \"\")] = mc_evt_df[knob].ms1\n",
    "\n",
    "# Turn GENIE unisim into multisims with 1 universe\n",
    "for knob in regen_systematics_sbnd_morph:\n",
    "    mc_evt_df[(knob, \"univ_0\", \"\", \"\", \"\", \"\", \"\", \"\")] = mc_evt_df[knob].morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify events into categories\n",
    "mc_evt_df.loc[:,'nuint_categ'] = get_int_category(mc_evt_df)\n",
    "mc_nu_df.loc[:,'nuint_categ'] = get_int_category(mc_nu_df)\n",
    "\n",
    "print(mc_evt_df.nuint_categ.value_counts())\n",
    "print(mc_nu_df.nuint_categ.value_counts()) # won't have -1 because nudf is all nu events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a variable to unfold, defined in variable_configs.py\n",
    "var_config = VariableConfig.muon_momentum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make dfs for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.clip is for including underflow events into the first bin and overflow events into the last bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total MC reco muon momentum: for fake data\n",
    "eps = 1e-8\n",
    "var_total_mc = mc_evt_df[var_config.var_evt_reco_col]\n",
    "var_total_mc = np.clip(var_total_mc, var_config.bins[0], var_config.bins[-1] - eps)\n",
    "weights_total_mc = mc_evt_df.loc[:, 'pot_weight']\n",
    "\n",
    "# --- all events, selected ---\n",
    "# mc_evt_df divided into topology modes for subtraction from data in future\n",
    "# first item in list is the signal topology\n",
    "mc_evt_df_divided = [mc_evt_df[mc_evt_df.nuint_categ == mode]for mode in mode_list]\n",
    "\n",
    "# Reco variable distribution for each 'nuint_categ' for stack plot and subtraction from the fake data\n",
    "var_per_nuint_categ_mc = [mc_evt_df[mc_evt_df.nuint_categ == mode][var_config.var_evt_reco_col]for mode in mode_list]\n",
    "var_per_nuint_categ_mc = [s.clip(var_config.bins[0], var_config.bins[-1] - eps) for s in var_per_nuint_categ_mc]\n",
    "weights_per_categ = [mc_evt_df.loc[mc_evt_df.nuint_categ == mode, 'pot_weight'] for mode in mode_list]\n",
    "\n",
    "# Reco variable distribution for each genie mode\n",
    "var_per_genie_mode_mc = [mc_evt_df[mc_evt_df.genie_mode == mode][var_config.var_evt_reco_col]for mode in genie_mode_list]\n",
    "var_per_genie_mode_mc = [s.clip(var_config.bins[0], var_config.bins[-1] - eps) for s in var_per_genie_mode_mc]\n",
    "weights_per_genie_mode = [mc_evt_df.loc[mc_evt_df.genie_mode == mode, 'pot_weight'] for mode in genie_mode_list]\n",
    "\n",
    "\n",
    "# --- signal events ---\n",
    "# selected, for response matrix\n",
    "# Signal event's reco muon momentum after the event selection\n",
    "var_signal_sel_reco = mc_evt_df[mc_evt_df.nuint_categ == 1][var_config.var_evt_reco_col]\n",
    "var_signal_sel_reco = np.clip(var_signal_sel_reco, var_config.bins[0], var_config.bins[-1] - eps)\n",
    "weight_signal = mc_evt_df.loc[mc_evt_df.nuint_categ == 1, 'pot_weight']\n",
    "\n",
    "# Signal event's true muon momentum after the event selection\n",
    "var_signal_sel_truth = mc_evt_df[mc_evt_df.nuint_categ == 1][var_config.var_evt_truth_col]\n",
    "var_signal_sel_truth = np.clip(var_signal_sel_truth, var_config.bins[0], var_config.bins[-1] - eps)\n",
    "weight_true_signal = mc_evt_df.loc[mc_evt_df.nuint_categ == 1, 'pot_weight']\n",
    "\n",
    "# total generated, for efficiency vector\n",
    "# Signal event's true muon momentum without event selection\n",
    "var_truth_signal = mc_nu_df[mc_nu_df.nuint_categ == 1][var_config.var_nu_col]\n",
    "var_truth_signal = np.clip(var_truth_signal, var_config.bins[0], var_config.bins[-1] - eps)\n",
    "weight_truth_signal = np.full_like(var_truth_signal, mc_pot_scale, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw true (before event selection) and reco (after event selection) muon momentum distributions of signal events.\n",
    "Print entries for double check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nevts_signal_truth, _, _ = plt.hist(var_truth_signal, bins=var_config.bins, weights=weight_truth_signal, histtype=\"step\", label=\"True Signal\")\n",
    "nevts_signal_sel_reco, _, _ = plt.hist(var_signal_sel_reco, bins=var_config.bins, weights=weight_signal, histtype=\"step\", label=\"Reco Selected Signal\", color=\"k\")\n",
    "nevts_signal_sel_truth, _, _ = plt.hist(var_signal_sel_truth, bins=var_config.bins, weights=weight_signal, histtype=\"step\", label=\"True Selected Signal\")\n",
    "print(nevts_signal_truth)\n",
    "print(nevts_signal_sel_reco)\n",
    "print(nevts_signal_sel_truth)\n",
    "plt.legend()\n",
    "plt.ylabel(\"Events\")\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[0])\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-sel_event_rates.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_2d = var_config.bins# = [np.array([0.2, 2]), np.array([0.2, 2])] # commented out lines for 1 bin MC closure test\n",
    "\n",
    "save_fig_name = \"{}/{}-reco_vs_true\".format(save_fig_dir, var_config.var_save_name)\n",
    "reco_vs_true = get_smear_matrix(var_signal_sel_truth, var_signal_sel_reco, bins_2d, var_labels=var_config.var_labels,\n",
    "                                save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "eff = get_eff(reco_vs_true, nevts_signal_truth)\n",
    "print(\"eff\")\n",
    "print(eff)\n",
    "\n",
    "save_fig_name = \"{}/{}-response_matrix\".format(save_fig_dir, var_config.var_save_name)\n",
    "Response = get_response_matrix(reco_vs_true, eff, var_config.bins, var_labels=var_config.var_labels,\n",
    "                               save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_covariance(cov_type, syst_name, n_univ, \n",
    "                   nevts_signal_sel_reco, var_signal_sel_truth, var_signal_sel_reco, bins, \n",
    "                   var_labels, save_fig=False, save_fig_name=None):\n",
    "\n",
    "    if cov_type == \"xsec\":\n",
    "        scale_factor = XSEC_UNIT\n",
    "        print(\"generating covariance for xsec, using scale factor: {}\".format(scale_factor))\n",
    "\n",
    "    elif cov_type == \"event\":\n",
    "        print(\"generating covariance for event rate\")\n",
    "        scale_factor = 1\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid cov_type: {}\".format(cov_type))\n",
    "\n",
    "    \n",
    "    signal_cv = nevts_signal_sel_reco * scale_factor # = Response @ true_signal\n",
    "\n",
    "    Covariance_Frac = np.zeros((len(signal_cv), len(signal_cv)))\n",
    "    Covariance = np.zeros((len(signal_cv), len(signal_cv)))\n",
    "\n",
    "    univ_events = []\n",
    "    for uidx in range(n_univ):\n",
    "        univ_col_evt = (syst_name, \"univ_{}\".format(uidx), \"\", \"\", \"\", \"\", \"\", \"\")\n",
    "        univ_col_mc = (syst_name, \"univ_{}\".format(uidx), \"\")\n",
    "\n",
    "        # ---- uncertainty on the signal rate ----\n",
    "        # GENIE syst need special treatment\n",
    "        # we don't want uncertainty on the xsec\n",
    "        # only consider its effect on the response matrix\n",
    "        if syst_name == \"GENIE\" and cov_type == \"xsec\":\n",
    "            true_signal_univ, _ = np.histogram(var_truth_signal, bins=var_config.bins, \n",
    "                                            weights=weight_truth_signal*mc_nu_df[mc_nu_df.nuint_categ == 1][univ_col_mc])\n",
    "            \n",
    "            # new response matrix for univ\n",
    "            reco_vs_true = get_smear_matrix(var_signal_sel_truth, var_signal_sel_reco, var_config.bins, \n",
    "                                            weights=mc_evt_df[mc_evt_df.nuint_categ == 1][univ_col_evt], plot=False)\n",
    "\n",
    "            eff = get_eff(reco_vs_true, true_signal_univ) \n",
    "\n",
    "            Response_univ = get_response_matrix(reco_vs_true, eff, bins, plot=False)\n",
    "            signal_univ = Response_univ @ nevts_signal_truth # note that we multiply the CV signal rate!\n",
    "\n",
    "        # for other systs, we just take the univ signal event rate\n",
    "        else:\n",
    "            signal_univ, _ = np.histogram(var_signal_sel_reco, bins=var_config.bins, \n",
    "                                             weights=mc_evt_df[mc_evt_df.nuint_categ == 1][univ_col_evt])\n",
    "\n",
    "        signal_univ = np.array(signal_univ) * scale_factor\n",
    "\n",
    "        # ---- uncertainty on the background rate ----\n",
    "        # loop over background categories\n",
    "        # + univ background - cv background\n",
    "        # note: cv background subtraction cancels out with the cv background subtraction for the cv event rate. \n",
    "        #       doing it anyways for the plot of universes on background subtracted event rate.\n",
    "        for this_mc_evt_df in mc_evt_df_divided[1:]:\n",
    "            weights = this_mc_evt_df[univ_col_evt].copy()\n",
    "            weights[np.isnan(weights)] = 1 ## IMPORTANT: make nan weights to 1. to ignore them\n",
    "            this_var = this_mc_evt_df[var_config.var_evt_reco_col]\n",
    "            this_var = np.clip(this_var, var_config.bins[0], var_config.bins[-1] - eps)\n",
    "            background_univ, _ = np.histogram(this_var, bins=var_config.bins, weights=weights)\n",
    "            background_cv, _ = np.histogram(this_var, bins=var_config.bins)\n",
    "            background_univ = np.array(background_univ) * scale_factor\n",
    "            background_cv = np.array(background_cv) * scale_factor\n",
    "            signal_univ += background_univ - background_cv\n",
    "\n",
    "        univ_events.append(signal_univ)\n",
    "        plt.hist(var_config.bin_centers, bins=var_config.bins, weights=signal_univ, histtype=\"step\", color=\"gray\")\n",
    "\n",
    "        # ---- covariance calculation ----\n",
    "        # I'm looping & calculating with the CV value for clarity, \n",
    "        # but techincally np.cov should also be fine under the assumption of gaussian universes that we're using\n",
    "        for i in range(len(signal_univ)):\n",
    "            for j in range(len(signal_univ)):\n",
    "                nom_i = signal_cv[i] \n",
    "                nom_j = signal_cv[j] \n",
    "\n",
    "                univ_i = signal_univ[i] \n",
    "                univ_j = signal_univ[j] \n",
    "\n",
    "                cov_entry = (univ_i - nom_i) * (univ_j - nom_j)\n",
    "                frac_cov_entry = ((univ_i - nom_i) / nom_i) * ( (univ_j - nom_j) / nom_j)\n",
    "\n",
    "                # TODO: this clipping exists in the uboone code, but I'm not sure why..?\n",
    "                # if cov_entry > 0:\n",
    "                #     this_cov = max( cov_entry, eps * scale_factor)\n",
    "                # else:\n",
    "                #     this_cov = min( cov_entry, eps * scale_factor)\n",
    "\n",
    "                # if frac_cov_entry > 0:\n",
    "                #     this_frac_cov = max( frac_cov_entry, eps * scale_factor)\n",
    "                # else:\n",
    "                #     this_frac_cov = min( frac_cov_entry, eps * scale_factor)\n",
    "\n",
    "                Covariance[i, j] += cov_entry\n",
    "                Covariance_Frac[i, j] += frac_cov_entry\n",
    "\n",
    "    plt.hist(var_config.bin_centers, bins=var_config.bins, weights=signal_cv, histtype=\"step\", color=\"black\", label=\"nominal_event\")\n",
    "\n",
    "    plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "    plt.xlabel(var_config.var_labels[0])\n",
    "    plt.ylabel(var_config.var_labels[1])\n",
    "    plt.title(syst_name)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    Covariance = Covariance / n_univ\n",
    "    Covariance_Frac = Covariance_Frac / n_univ\n",
    "    Correlation = np.zeros_like(Covariance)\n",
    "    for i in range(len(signal_cv)):\n",
    "        for j in range(len(signal_cv)):\n",
    "            Correlation[i, j] = Covariance[i, j] / (np.sqrt(Covariance[i, i]) * np.sqrt(Covariance[j, j]))\n",
    "\n",
    "    if save_fig:\n",
    "        plt.savefig(\"{}.pdf\".format(save_fig_name), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    return {\"Covariance_Frac\": Covariance_Frac, \n",
    "            \"Covariance\": Covariance,\n",
    "            \"Correlation\": Correlation,\n",
    "            \"cv_events\": signal_cv,\n",
    "            \"univ_events\": univ_events,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretty heatmap plotter\n",
    "\n",
    "unif_bin = np.linspace(0., float(len(var_config.bins) - 1), len(var_config.bins))\n",
    "extent = [unif_bin[0], unif_bin[-1], unif_bin[0], unif_bin[-1]]\n",
    "\n",
    "x_edges = np.array(var_config.bins)\n",
    "y_edges = np.array(var_config.bins)\n",
    "x_tick_positions = (unif_bin[:-1] + unif_bin[1:]) / 2\n",
    "y_tick_positions = (unif_bin[:-1] + unif_bin[1:]) / 2\n",
    "\n",
    "x_labels = bin_range_labels(x_edges)\n",
    "y_labels = bin_range_labels(y_edges)\n",
    "\n",
    "def plot_heatmap(matrix, title, plot_labels=var_config.var_labels, save_fig=False, save_fig_name=None):\n",
    "    plt.imshow(matrix, extent=extent, origin=\"lower\")\n",
    "    plt.colorbar()\n",
    "    plt.xticks(x_tick_positions, x_labels, rotation=45, ha=\"right\")\n",
    "    plt.yticks(y_tick_positions, y_labels)\n",
    "    plt.xlabel(plot_labels[0])\n",
    "    plt.ylabel(plot_labels[1])\n",
    "    for i in range(matrix.shape[0]):      # rows (y)\n",
    "        for j in range(matrix.shape[1]):  # columns (x)\n",
    "            value = matrix[i, j]\n",
    "            if not np.isnan(value):  # skip NaNs\n",
    "                plt.text(\n",
    "                    j + 0.5, i + 0.5,\n",
    "                    f\"{value:.2f}\",\n",
    "                    ha=\"center\", va=\"center\",   \n",
    "                    color=get_text_color(value),\n",
    "                    fontsize=10\n",
    "                )\n",
    "    plt.title(title)\n",
    "    if save_fig:\n",
    "        plt.savefig(\"{}.pdf\".format(save_fig_name), bbox_inches='tight')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MC Stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the average of universes' weights is ~ CV value\n",
    "univ_avg = mc_evt_df.MCstat.mean(axis=1)\n",
    "fig, ax = plt.subplots(2,1, figsize=(6, 6), sharex=True, gridspec_kw={'height_ratios': [2, 1]})\n",
    "cv_events, _, _ = ax[0].hist(mc_evt_df[var_config.var_evt_reco_col], bins=var_config.bins, histtype=\"step\", color=\"black\", label=\"nominal_event\")\n",
    "univ_avg_events, _, _ = ax[0].hist(mc_evt_df[var_config.var_evt_reco_col], bins=var_config.bins, weights=univ_avg, histtype=\"step\", color=\"red\", label=\"univ_avg\")\n",
    "ax[0].set_xlim(var_config.bins[0], var_config.bins[-1])\n",
    "ax[0].set_ylabel(\"Events\")\n",
    "ax[0].legend()\n",
    "\n",
    "bin_centers = (var_config.bins[1:] + var_config.bins[:-1]) / 2\n",
    "ratio = univ_avg_events/cv_events\n",
    "ax[1].hist(bin_centers, bins=var_config.bins, weights=ratio, histtype=\"step\", color=\"black\")\n",
    "ax[1].set_xlim(var_config.bins[0], var_config.bins[-1])\n",
    "ax[1].set_xlabel(var_config.var_labels[0])\n",
    "ax[1].set_ylabel(\"univ_avg/CV\")\n",
    "ax[1].set_xlabel(var_config.var_labels[0])\n",
    "ax[1].set_ylim(0.9, 1.1)\n",
    "\n",
    "tolerance = 0.05\n",
    "if np.all(np.abs(ratio - 1) < tolerance):\n",
    "    print(\"The average of universes' weights is within the tolerance of the CV value\")\n",
    "else:\n",
    "    print(\"The average of universes' weights is not within the tolerance of the CV value\")\n",
    "\n",
    "for uidx in range(100):\n",
    "    # print(uidx)\n",
    "    plt.hist(mc_evt_df[var_config.var_evt_reco_col], bins=var_config.bins, weights=mc_evt_df[\"MCstat\"][f\"univ_{uidx}\"], histtype=\"step\", color=\"gray\")\n",
    "\n",
    "plt.hist(mc_evt_df[var_config.var_evt_reco_col], bins=var_config.bins, histtype=\"step\", color=\"black\", label=\"nominal_event\")\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_type = \"xsec\"\n",
    "syst_name = \"MCstat\"\n",
    "n_univ = 100\n",
    "labels = [var_config.var_labels[1], \"Flux Integrated Event Rate\"]\n",
    "\n",
    "save_fig_name = \"{}/{}-{}-mcstat_univ_events\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "ret_mcstat = get_covariance(cov_type, syst_name, n_univ, \n",
    "                            nevts_signal_sel_reco, var_signal_sel_truth, var_signal_sel_reco, var_config.bins, \n",
    "                            labels, save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sign of fractional covariance is different from the other two?\n",
    "save_fig_name = \"{}/{}-{}-mcstat_covariance\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_heatmap(ret_mcstat[\"Covariance\"], \"Covariance - mcstat\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "save_fig_name = \"{}/{}-{}-mcstat_covariance_frac\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_heatmap(ret_mcstat[\"Covariance_Frac\"], \"Fractional Covariance - mcstat\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "save_fig_name = \"{}/{}-{}-mcstat_correlation\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_heatmap(ret_mcstat[\"Correlation\"], \"Correlation - mcstat\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_type = \"xsec\"\n",
    "syst_name = \"Flux\"\n",
    "n_univ = 1000\n",
    "\n",
    "labels = [var_config.var_labels[1], \"Flux Integrated Event Rate\"]\n",
    "\n",
    "save_fig_name = \"{}/{}-{}-flux_univ_events\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "ret_flux = get_covariance(cov_type, syst_name, n_univ, \n",
    "                          nevts_signal_sel_reco, var_signal_sel_truth, var_signal_sel_reco, var_config.bins, \n",
    "                          labels, save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_name = \"{}/{}-{}-flux_covariance\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_heatmap(ret_flux[\"Covariance\"], \"Covariance - Flux\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "save_fig_name = \"{}/{}-{}-flux_covariance_frac\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_heatmap(ret_flux[\"Covariance_Frac\"], \"Fractional Covariance - Flux\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "save_fig_name = \"{}/{}-{}-flux_correlation\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_heatmap(ret_flux[\"Correlation\"], \"Correlation - Flux\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENIE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multisims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syst_type = \"xsec\"\n",
    "syst_name = \"GENIE\"\n",
    "n_univ = 100\n",
    "\n",
    "labels = [var_config.var_labels[1], \"Flux Integrated Event Rate\"]\n",
    "\n",
    "save_fig_name = \"{}/{}-{}-genie_univ_events\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "ret_genie = get_covariance(cov_type, syst_name, n_univ, \n",
    "                          nevts_signal_sel_reco, var_signal_sel_truth, var_signal_sel_reco, var_config.bins, \n",
    "                          labels, save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_name = \"{}/{}-{}-genie_covariance\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_heatmap(ret_genie[\"Covariance\"], \"Covariance - GENIE\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "save_fig_name = \"{}/{}-{}-genie_covariance_frac\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_heatmap(ret_genie[\"Covariance_Frac\"], \"Fractional Covariance - GENIE\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "save_fig_name = \"{}/{}-{}-genie_correlation\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_heatmap(ret_genie[\"Correlation\"], \"Correlation - GENIE\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unisims (morph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_type = \"event\"\n",
    "n_univ = 1\n",
    "for kidx, knob in enumerate(regen_systematics_sbnd_morph):\n",
    "    syst_name = knob\n",
    "\n",
    "    labels = [var_config.var_labels[1], \"Flux Integrated Event Rate\"]\n",
    "\n",
    "    save_fig_name = \"{}/{}-{}-geniemorph_univ_events\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "    ret_geniemorph = get_covariance(cov_type, syst_name, n_univ, \n",
    "                            nevts_signal_sel_reco, var_signal_sel_truth, var_signal_sel_reco, var_config.bins, \n",
    "                            labels, save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "\n",
    "    if kidx == 0:\n",
    "        GENIEmorph_Frac_Covariance = ret_geniemorph[\"Covariance_Frac\"]\n",
    "    else:\n",
    "        GENIEmorph_Frac_Covariance += ret_geniemorph[\"Covariance_Frac\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(GENIEmorph_Frac_Covariance, \"GENIE Morph Fractional Covariance\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multisigma\n",
    "\n",
    "- we treat this as a unisim using 1 sigma "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regen_systematics_sbnd_multisigma)\n",
    "knob = regen_systematics_sbnd_multisigma[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for knob in regen_systematics_sbnd_multisigma[:3]:\n",
    "    plt.hist(var_signal_sel_reco, bins=var_config.bins, weights=mc_evt_df[mc_evt_df.nuint_categ == 1][knob].ps1, histtype=\"step\", \n",
    "            color=\"C0\", label=\"ps1\")\n",
    "    plt.hist(var_signal_sel_reco, bins=var_config.bins, weights=mc_evt_df[mc_evt_df.nuint_categ == 1][knob].ps2, histtype=\"step\", \n",
    "            color=\"C0\", label=\"ps2\", alpha=0.75)\n",
    "    plt.hist(var_signal_sel_reco, bins=var_config.bins, weights=mc_evt_df[mc_evt_df.nuint_categ == 1][knob].ps3, histtype=\"step\", \n",
    "            color=\"C0\", label=\"ps3\", alpha=0.5)\n",
    "    plt.hist(var_signal_sel_reco, bins=var_config.bins, weights=mc_evt_df[mc_evt_df.nuint_categ == 1][knob].ms1, histtype=\"step\", \n",
    "            color=\"C0\", label=\"ms1\", linestyle=\"--\")\n",
    "    plt.hist(var_signal_sel_reco, bins=var_config.bins, weights=mc_evt_df[mc_evt_df.nuint_categ == 1][knob].ms2, histtype=\"step\", \n",
    "            color=\"C0\", label=\"ms2\", linestyle=\"--\", alpha=0.75)\n",
    "    plt.hist(var_signal_sel_reco, bins=var_config.bins, weights=mc_evt_df[mc_evt_df.nuint_categ == 1][knob].ms3, histtype=\"step\", \n",
    "            color=\"C0\", label=\"ms3\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    # TODO: is there any purpose of using cv? seems redundant...\n",
    "    # plt.hist(var_signal_sel_reco, bins=var_config.bins, histtype=\"step\", color=\"black\", label=\"nominal_event\")\n",
    "    plt.hist(var_signal_sel_reco, bins=var_config.bins, weights=mc_evt_df[mc_evt_df.nuint_categ == 1][knob].cv, histtype=\"step\", color=\"black\", label=\"nominal_event\")\n",
    "\n",
    "    plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "    plt.xlabel(var_config.var_labels[0])\n",
    "    plt.ylabel(var_config.var_labels[1])\n",
    "    plt.title(knob)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_type = \"event\"\n",
    "syst_name = knob\n",
    "n_univ = 2\n",
    "\n",
    "labels = [var_config.var_labels[1], \"Flux Integrated Event Rate\"]\n",
    "\n",
    "save_fig_name = \"{}/{}-{}-genie_univ_events\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "ret_geniemultisigma = get_covariance(cov_type, syst_name, n_univ, \n",
    "                          nevts_signal_sel_reco, var_signal_sel_truth, var_signal_sel_reco, var_config.bins, \n",
    "                          labels, save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_name = \"{}/{}-{}-genie_covariance\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_heatmap(ret_geniemultisigma[\"Covariance\"], \"Covariance - genie\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "save_fig_name = \"{}/{}-{}-genie_covariance_frac\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_heatmap(ret_geniemultisigma[\"Covariance_Frac\"], \"Fractional Covariance - genie\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "save_fig_name = \"{}/{}-{}-genie_correlation\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_heatmap(ret_geniemultisigma[\"Correlation\"], \"Correlation - genie\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- justification for the unisim treatment\n",
    "# throw multivariate normal distribution to the bin center using 1 sigma,\n",
    "# show that the 2 and 3 sigma are close to the 2 and 3 sigmas of the distribution, per bin\n",
    "\n",
    "n_cv, _ = np.histogram(var_signal_sel_reco, bins=var_config.bins, weights=mc_evt_df[mc_evt_df.nuint_categ == 1][knob].cv)\n",
    "universes_from_1sigma = np.random.multivariate_normal(n_cv, ret_geniemultisigma[\"Covariance\"], size=1000)\n",
    "for i in range(len(universes_from_1sigma)):\n",
    "    plt.hist(var_config.bin_centers, bins=var_config.bins, weights=universes_from_1sigma[i], histtype=\"step\", color=\"gray\")\n",
    "\n",
    "n_cv , _, _ = plt.hist(var_config.bin_centers, bins=var_config.bins, weights=n_cv, histtype=\"step\", color=\"black\", label=\"CV\")\n",
    "n_ps1, _, _ = plt.hist(var_signal_sel_reco, bins=var_config.bins, weights=mc_evt_df[mc_evt_df.nuint_categ == 1][knob].ps1, histtype=\"step\", \n",
    "        color=\"C0\", label=\"ps1\")\n",
    "n_ps2, _, _ = plt.hist(var_signal_sel_reco, bins=var_config.bins, weights=mc_evt_df[mc_evt_df.nuint_categ == 1][knob].ps2, histtype=\"step\", \n",
    "        color=\"C0\", label=\"ps2\", alpha=0.75)\n",
    "n_ps3, _, _ = plt.hist(var_signal_sel_reco, bins=var_config.bins, weights=mc_evt_df[mc_evt_df.nuint_categ == 1][knob].ps3, histtype=\"step\", \n",
    "        color=\"C0\", label=\"ps3\", alpha=0.5)\n",
    "n_ms1, _, _ = plt.hist(var_signal_sel_reco, bins=var_config.bins, weights=mc_evt_df[mc_evt_df.nuint_categ == 1][knob].ms1, histtype=\"step\", \n",
    "        color=\"C0\", label=\"ms1\", linestyle=\"--\")\n",
    "n_ms2, _, _ = plt.hist(var_signal_sel_reco, bins=var_config.bins, weights=mc_evt_df[mc_evt_df.nuint_categ == 1][knob].ms2, histtype=\"step\", \n",
    "        color=\"C0\", label=\"ms2\", linestyle=\"--\", alpha=0.75)\n",
    "n_ms3, _, _ = plt.hist(var_signal_sel_reco, bins=var_config.bins, weights=mc_evt_df[mc_evt_df.nuint_categ == 1][knob].ms3, histtype=\"step\", \n",
    "        color=\"C0\", label=\"ms3\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[0])\n",
    "plt.ylabel(var_config.var_labels[1])\n",
    "plt.title(knob)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_idx = 1\n",
    "\n",
    "# distribuion of weights\n",
    "this_wgts = universes_from_1sigma[:, bin_idx]\n",
    "plt.hist(this_wgts, bins=21, histtype=\"step\", color=\"black\", label=\"weights from CAF ps1/ms1\")\n",
    "\n",
    "labels = [\"3$\\\\sigma$\", \"2$\\\\sigma$\", \"1$\\\\sigma$\"]\n",
    "\n",
    "# sig levels from thrown universes\n",
    "wgts_sig = np.percentile(this_wgts, np.array([(1-0.997)/2., (1-0.95)/2., (1-0.68)/2.,\n",
    "                                      0.5+(0.68)/2., 0.5+(0.95)/2., 0.5+(0.997)/2.])*100)\n",
    "wgts_cv = np.percentile(this_wgts, 50)\n",
    "plt.axvline(wgts_cv, color=\"green\", label=\"CV from weights\")\n",
    "plt.text(wgts_cv*1.01, plt.ylim()[1]*0.9, \"$\\\\mu$\", color=\"green\", fontsize=12)\n",
    "for sidx, s in enumerate(wgts_sig):\n",
    "    if sidx <= 2:\n",
    "        linestyle = \"-\"\n",
    "        plt.axvline(s, color=\"C2\", linestyle=linestyle, alpha=0.5+0.25*(sidx%3))\n",
    "        plt.text(s, plt.ylim()[1]*0.9, labels[::-1][sidx%3], color=\"C2\", fontsize=12)\n",
    "    else:\n",
    "        linestyle = \"--\"\n",
    "        plt.axvline(s, color=\"C2\", linestyle=linestyle, alpha=1-0.25*(sidx%3))\n",
    "        plt.text(s, plt.ylim()[1]*0.9, labels[sidx%3], color=\"C2\", fontsize=12)\n",
    "\n",
    "# sig levels from cafs\n",
    "plt.axvline(n_cv[bin_idx], color=\"blue\")\n",
    "plt.text(n_cv[bin_idx], plt.ylim()[1]*0.8, \"cv\", color=\"blue\", fontsize=12)\n",
    "plt.axvline(n_ps1[bin_idx], color=\"C0\")\n",
    "plt.text(n_ps1[bin_idx], plt.ylim()[1]*0.8, \"ps1\", color=\"C0\", fontsize=12)\n",
    "plt.axvline(n_ps2[bin_idx], color=\"C0\", alpha=0.75)\n",
    "plt.text(n_ps2[bin_idx], plt.ylim()[1]*0.8, \"ps2\", color=\"C0\", fontsize=12)\n",
    "plt.axvline(n_ps3[bin_idx], color=\"C0\", alpha=0.5)\n",
    "plt.text(n_ps3[bin_idx], plt.ylim()[1]*0.8, \"ps3\", color=\"C0\", fontsize=12)\n",
    "plt.axvline(n_ms1[bin_idx], color=\"C0\", linestyle=\"--\")\n",
    "plt.text(n_ms1[bin_idx], plt.ylim()[1]*0.8, \"ms1\", color=\"C0\", fontsize=12)\n",
    "plt.axvline(n_ms2[bin_idx], color=\"C0\", linestyle=\"--\", alpha=0.75)\n",
    "plt.text(n_ms2[bin_idx], plt.ylim()[1]*0.8, \"ms2\", color=\"C0\", fontsize=12)\n",
    "plt.axvline(n_ms3[bin_idx], color=\"C0\", linestyle=\"--\", alpha=0.5)\n",
    "plt.text(n_ms3[bin_idx], plt.ylim()[1]*0.8, \"ms3\", color=\"C0\", fontsize=12)\n",
    "plt.xlabel(var_config.var_labels[0] + \", Bin \" + str(bin_idx))\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "plt.title(knob)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add cov from all multisigma knobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_type = \"event\"\n",
    "n_univ = 2\n",
    "for kidx, knob in enumerate(regen_systematics_sbnd_multisigma):\n",
    "    syst_name = knob\n",
    "\n",
    "    labels = [var_config.var_labels[1], \"Flux Integrated Event Rate\"]\n",
    "\n",
    "    save_fig_name = \"{}/{}-{}-geniemultisigma_univ_events\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "    ret_geniemultisigma = get_covariance(cov_type, syst_name, n_univ, \n",
    "                            nevts_signal_sel_reco, var_signal_sel_truth, var_signal_sel_reco, var_config.bins, \n",
    "                            labels, save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "\n",
    "    if kidx == 0:\n",
    "        GENIEmultisigma_Frac_Covariance = ret_geniemultisigma[\"Covariance_Frac\"]\n",
    "    else:\n",
    "        GENIEmultisigma_Frac_Covariance += ret_geniemultisigma[\"Covariance_Frac\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(GENIEmultisigma_Frac_Covariance, \"GENIE Multisigma Fractional Covariance\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add all GENIE cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENIE_Frac_Covariance = ret_genie[\"Covariance_Frac\"] + GENIEmorph_Frac_Covariance + GENIEmultisigma_Frac_Covariance\n",
    "plot_heatmap(GENIE_Frac_Covariance, \"GENIE Fractional Covariance\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add fractional covariance of all systs, then multiply by the CV value to get the covariance\n",
    "Total_Covariance_Frac = ret_flux[\"Covariance_Frac\"] + GENIE_Frac_Covariance + ret_mcstat[\"Covariance_Frac\"]\n",
    "\n",
    "Total_Covariance = np.zeros_like(Total_Covariance_Frac)\n",
    "for i in range(len(var_config.bins)-1):\n",
    "    for j in range(len(var_config.bins)-1):\n",
    "        Total_Covariance[i, j] = Total_Covariance_Frac[i, j] * (nevts_signal_sel_reco[i] * nevts_signal_sel_reco[j]) * XSEC_UNIT**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_name = \"{}/{}-{}-total_covariance_frac\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_heatmap(Total_Covariance_Frac, \"Total Fractional Covariance\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fractional uncertainty\n",
    "frac_uncert_flux = np.sqrt(np.diag(ret_flux[\"Covariance_Frac\"]))\n",
    "frac_uncert_genie = np.sqrt(np.diag(GENIE_Frac_Covariance))\n",
    "# frac_uncert_genie = np.sqrt(np.diag(ret_genie[\"Covariance_Frac\"]))\n",
    "frac_uncert_mcstat = np.sqrt(np.diag(ret_mcstat[\"Covariance_Frac\"]))\n",
    "frac_uncert_total = np.sqrt(np.diag(Total_Covariance_Frac))\n",
    "\n",
    "plt.hist(var_config.bin_centers, bins=var_config.bins, weights=frac_uncert_flux*1e2, histtype=\"step\", color=\"C0\", label=\"Flux\")\n",
    "plt.hist(var_config.bin_centers, bins=var_config.bins, weights=frac_uncert_genie*1e2, histtype=\"step\", color=\"C1\", label=\"GENIE\")\n",
    "plt.hist(var_config.bin_centers, bins=var_config.bins, weights=frac_uncert_mcstat*1e2, histtype=\"step\", color=\"C2\", label=\"MCstat\")\n",
    "plt.hist(var_config.bin_centers, bins=var_config.bins, weights=frac_uncert_total*1e2, histtype=\"step\", color=\"k\", label=\"Total\")\n",
    "\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[0])\n",
    "plt.ylabel(\"Uncertainty [%]\")\n",
    "plt.legend()\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-uncertainty_breakdown.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Singal distribution with error bars from diagonal components of covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bin centers for error bars\n",
    "frac_uncert = np.sqrt(np.diag(Total_Covariance_Frac))\n",
    "plt.errorbar(bin_centers, nevts_signal_sel_reco*XSEC_UNIT, yerr=frac_uncert*nevts_signal_sel_reco*XSEC_UNIT, fmt='o', color='black', label='Subtracted (syst. error)', capsize=3)\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[0])\n",
    "plt.ylabel(\"Events\")\n",
    "plt.legend()\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-bkg_subtracted_event_rates.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfolding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closure test \n",
    "- use MC signal as fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect topology breakdown\n",
    "plt.figure(figsize=(8, 6))\n",
    "mc_stack, _, _ = plt.hist(var_per_nuint_categ_mc,\n",
    "                            bins=var_config.bins,\n",
    "                            weights=weights_per_categ,\n",
    "                            stacked=True,\n",
    "                            color=colors,\n",
    "                            label=mode_labels,\n",
    "                            edgecolor='none',\n",
    "                            linewidth=0,\n",
    "                            density=False,\n",
    "                            histtype='stepfilled')\n",
    "\n",
    "totmc, bin_edges = np.histogram(var_total_mc, bins=var_config.bins, weights=weights_total_mc)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# use MC as fake data for closure test\n",
    "fake_data = totmc\n",
    "fake_data_err = np.sqrt(totmc)\n",
    "# plt.step(bin_edges[:-1], fake_data, where='post', label=\"Data\")  # line\n",
    "plt.errorbar(bin_centers, fake_data, yerr=fake_data_err, fmt='o', color='black')  # error bars\n",
    "\n",
    "accum_sum = [np.sum(data) for data in mc_stack]\n",
    "accum_sum = [0.] + accum_sum\n",
    "total_sum = accum_sum[-1]\n",
    "individual_sums = [accum_sum[i + 1] - accum_sum[i] for i in range(len(accum_sum) - 1)]\n",
    "fractions = [(count / total_sum) * 100 for count in individual_sums]\n",
    "legend_labels = [f\"{label} ({frac:.1f}%)\" for label, frac in zip(mode_labels[::-1], fractions[::-1])]\n",
    "legend_labels.append(\"Fake Data\")\n",
    "plt.legend(legend_labels, loc='upper left', fontsize=10, frameon=False, ncol=3, bbox_to_anchor=(0.05, 0.98))\n",
    "\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[1])\n",
    "plt.ylim(0., 1.3 * fake_data.max())\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-topology_breakdown.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect GENIE mode breakdown\n",
    "plt.figure(figsize=(8, 6))\n",
    "mc_stack, _, _ = plt.hist(var_per_genie_mode_mc,\n",
    "                            bins=var_config.bins,\n",
    "                            weights=weights_per_genie_mode,\n",
    "                            stacked=True,\n",
    "                            color=genie_mode_colors,\n",
    "                            label=genie_mode_labels,\n",
    "                            edgecolor='none',\n",
    "                            linewidth=0,\n",
    "                            density=False,\n",
    "                            histtype='stepfilled')\n",
    "\n",
    "totmc, bin_edges = np.histogram(var_total_mc, bins=var_config.bins, weights=weights_total_mc)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# use MC as fake data for closure test\n",
    "fake_data = totmc\n",
    "fake_data_err = np.sqrt(totmc)\n",
    "# plt.step(bin_edges[:-1], fake_data, where='post', label=\"Data\")  # line\n",
    "plt.errorbar(bin_centers, fake_data, yerr=fake_data_err, fmt='o', color='black')  # error bars\n",
    "\n",
    "accum_sum = [np.sum(data) for data in mc_stack]\n",
    "accum_sum = [0.] + accum_sum\n",
    "total_sum = accum_sum[-1]\n",
    "individual_sums = [accum_sum[i + 1] - accum_sum[i] for i in range(len(accum_sum) - 1)]\n",
    "fractions = [(count / total_sum) * 100 for count in individual_sums]\n",
    "legend_labels = [f\"{label} ({frac:.1f}%)\" for label, frac in zip(genie_mode_labels[::-1], fractions[::-1])]\n",
    "legend_labels.append(\"Fake Data\")\n",
    "plt.legend(legend_labels, loc='upper left', fontsize=10, frameon=False, ncol=3, bbox_to_anchor=(0.05, 0.98))\n",
    "\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[1])\n",
    "plt.ylim(0., 1.3 * fake_data.max())\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-genie_mode_breakdown.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closure test -- just use MC stat uncertainty\n",
    "C_type = 2\n",
    "Norm_type = 0.5\n",
    "Measured = nevts_signal_sel_reco * XSEC_UNIT # = fake_data - fake_background\n",
    "Model = nevts_signal_truth * XSEC_UNIT\n",
    "Covariance = ret_mcstat[\"Covariance\"]\n",
    "# Covariance = ret_flux[\"Covariance\"]\n",
    "unfold = WienerSVD(Response, Model, Measured, Covariance, C_type, Norm_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfold.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfold['unfold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfold['UnfoldCov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2(data, model, cov):\n",
    "    return (data - model) @ np.linalg.inv(cov) @ (data - model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfold['unfold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfold['AddSmear'] @ nevts_signal_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unfold = unfold['unfold']\n",
    "UnfoldCov = unfold['UnfoldCov']\n",
    "Unfold_uncert = np.sqrt(np.diag(UnfoldCov))\n",
    "\n",
    "step_handle, = plt.step(bin_edges, np.append(Unfold, Unfold[-1]), where='post', label='Unfolded', color='black')\n",
    "bar_handle = plt.bar(\n",
    "    bin_centers,\n",
    "    2*Unfold_uncert,\n",
    "    width=(bin_edges[1] - bin_edges[0]) * 1.,\n",
    "    bottom=Unfold - Unfold_uncert,\n",
    "    color='gray',\n",
    "    alpha=0.5,\n",
    "    linewidth=0,\n",
    "    label='Unfolded Stat. error (box)'\n",
    ")\n",
    "reco_handle, = plt.plot(bin_centers, Measured, 'o', label='Reco. signal')\n",
    "Model_smear = unfold['AddSmear'] @ Model\n",
    "true_handle, = plt.plot(bin_centers, Model_smear, 'o', label='$A_c \\\\times$ True signal')\n",
    "\n",
    "# chi2_val = chi2(Unfold, Model_smear, UnfoldCov)\n",
    "# plt.text(0.95, 0.50, f\"$ \\\\chi^2 = $ {chi2_val:.2f}\", ha='right', va='center', \n",
    "#          transform=plt.gca().transAxes, fontsize=12)\n",
    "\n",
    "# Custom order for legend\n",
    "handles = [step_handle, bar_handle, reco_handle, true_handle]\n",
    "labels = [\n",
    "    'Unfolded',\n",
    "    'Unfolded error',\n",
    "    'Reco. signal',\n",
    "    '$A_c \\\\times$True signal'\n",
    "]\n",
    "\n",
    "plt.legend(handles, labels)\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[0])\n",
    "# plt.ylim(0., 5000.)\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-unfolded_event_rates.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_name = \"{}/{}-{}-add_smear\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_labels = [var_config.var_labels[2], var_config.var_labels[1]]\n",
    "plot_heatmap(unfold[\"AddSmear\"], \"$A_c$\", plot_labels=plot_labels,\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake Data Tests\n",
    "\n",
    "- use alternate MC as fake data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MEC scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mec_scale = 2\n",
    "weights_fake_data = np.ones(len(var_total_mc))\n",
    "weights_fake_data[mc_evt_df.genie_mode == 10] = mec_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "mc_stack, _, _ = plt.hist(var_per_nuint_categ_mc,\n",
    "                            bins=var_config.bins,\n",
    "                            weights=weights_per_categ,\n",
    "                            stacked=True,\n",
    "                            color=colors,\n",
    "                            label=mode_labels,\n",
    "                            edgecolor='none',\n",
    "                            linewidth=0,\n",
    "                            density=False,\n",
    "                            histtype='stepfilled')\n",
    "totmc, bin_edges = np.histogram(var_total_mc, bins=var_config.bins, weights=weights_total_mc * weights_fake_data)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# use MC as fake data for closure test\n",
    "fake_data = totmc\n",
    "fake_data_err = np.sqrt(totmc)\n",
    "plt.errorbar(bin_centers, fake_data, yerr=fake_data_err, fmt='o', color='black')  # error bars\n",
    "\n",
    "background_cv = mc_stack[-1] - mc_stack[0]\n",
    "# plt.hist(bin_centers, weights=fake_data - background_cv, bins=var_config.bins, histtype=\"step\", color=\"k\", label=\"Background\")\n",
    "\n",
    "accum_sum = [np.sum(data) for data in mc_stack]\n",
    "accum_sum = [0.] + accum_sum\n",
    "total_sum = accum_sum[-1]\n",
    "individual_sums = [accum_sum[i + 1] - accum_sum[i] for i in range(len(accum_sum) - 1)]\n",
    "fractions = [(count / total_sum) * 100 for count in individual_sums]\n",
    "legend_labels = [f\"{label} ({frac:.1f}%)\" for label, frac in zip(mode_labels[::-1], fractions[::-1])]\n",
    "legend_labels.append(\"Fake Data (MEC x{})\".format(mec_scale))\n",
    "plt.legend(legend_labels, loc='upper left', fontsize=10, frameon=False, ncol=3, bbox_to_anchor=(0.05, 0.98))\n",
    "\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[1])\n",
    "plt.ylim(0., 1.3 * fake_data.max())\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-topology_breakdown.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect GENIE mode breakdown\n",
    "plt.figure(figsize=(8, 6))\n",
    "mc_stack, _, _ = plt.hist(var_per_genie_mode_mc,\n",
    "                            bins=var_config.bins,\n",
    "                            weights=weights_per_genie_mode,\n",
    "                            stacked=True,\n",
    "                            color=genie_mode_colors,\n",
    "                            label=genie_mode_labels,\n",
    "                            edgecolor='none',\n",
    "                            linewidth=0,\n",
    "                            density=False,\n",
    "                            histtype='stepfilled')\n",
    "\n",
    "totmc, bin_edges = np.histogram(var_total_mc, bins=var_config.bins, weights=weights_total_mc * weights_fake_data)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# use MC as fake data for closure test\n",
    "fake_data = totmc\n",
    "fake_data_err = np.sqrt(totmc)\n",
    "# plt.step(bin_edges[:-1], fake_data, where='post', label=\"Data\")  # line\n",
    "plt.errorbar(bin_centers, fake_data, yerr=fake_data_err, fmt='o', color='black')  # error bars\n",
    "\n",
    "accum_sum = [np.sum(data) for data in mc_stack]\n",
    "accum_sum = [0.] + accum_sum\n",
    "total_sum = accum_sum[-1]\n",
    "individual_sums = [accum_sum[i + 1] - accum_sum[i] for i in range(len(accum_sum) - 1)]\n",
    "fractions = [(count / total_sum) * 100 for count in individual_sums]\n",
    "legend_labels = [f\"{label} ({frac:.1f}%)\" for label, frac in zip(genie_mode_labels[::-1], fractions[::-1])]\n",
    "legend_labels.append(\"Fake Data (MEC x{})\".format(mec_scale))\n",
    "plt.legend(legend_labels, loc='upper left', fontsize=10, frameon=False, ncol=3, bbox_to_anchor=(0.05, 0.98))\n",
    "\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[1])\n",
    "plt.ylim(0., 1.3 * fake_data.max())\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-genie_mode_breakdown.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake data test -- MC stat + xsec cov\n",
    "C_type = 2\n",
    "Norm_type = 0.5\n",
    "Measured = fake_data * XSEC_UNIT - background_cv * XSEC_UNIT\n",
    "Model = nevts_signal_truth * XSEC_UNIT\n",
    "\n",
    "# use MC stat and xsec cov\n",
    "Covariance_Frac = ret_genie[\"Covariance_Frac\"] + ret_mcstat[\"Covariance_Frac\"]\n",
    "\n",
    "Covariance = np.zeros_like(Covariance_Frac)\n",
    "for i in range(len(var_config.bins)-1):\n",
    "    for j in range(len(var_config.bins)-1):\n",
    "        Covariance[i, j] = Covariance_Frac[i, j] * (nevts_signal_sel_reco[i] * nevts_signal_sel_reco[j]) * XSEC_UNIT**2\n",
    "\n",
    "unfold = WienerSVD(Response, Model, Measured, Covariance, C_type, Norm_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true cross section for alt MC used asfake data\n",
    "var_fakedata_signal_truth = mc_nu_df[mc_nu_df.nuint_categ == 1][var_config.var_nu_col]\n",
    "var_fakedata_signal_truth = np.clip(var_fakedata_signal_truth, var_config.bins[0], var_config.bins[-1] - eps)\n",
    "weight_fakedata_signal_truth = np.ones(len(var_fakedata_signal_truth))\n",
    "nevts_fakedata_signal_truth, _, _ = plt.hist(var_fakedata_signal_truth, bins=var_config.bins, weights=weight_fakedata_signal_truth, histtype=\"step\", label=\"True Signal\")\n",
    "weight_fakedata_signal_truth[mc_nu_df[mc_nu_df.nuint_categ == 1].genie_mode == 10] = mec_scale\n",
    "nevts_fakedata_signal_truth, _, _ = plt.hist(var_fakedata_signal_truth, bins=var_config.bins, weights=weight_fakedata_signal_truth, histtype=\"step\", label=\"MEC x2 True Signal\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "Unfold = unfold['unfold']\n",
    "UnfoldCov = unfold['UnfoldCov']\n",
    "Unfold_uncert = np.sqrt(np.diag(UnfoldCov))\n",
    "\n",
    "step_handle, = plt.step(bin_edges, np.append(Unfold, Unfold[-1]), where='post', label='Unfolded', color='black')\n",
    "bar_handle = plt.bar(\n",
    "    bin_centers,\n",
    "    2*Unfold_uncert,\n",
    "    width=(bin_edges[1] - bin_edges[0]) * 1.,\n",
    "    bottom=Unfold - Unfold_uncert,\n",
    "    color='gray',\n",
    "    alpha=0.5,\n",
    "    linewidth=0,\n",
    "    label='Unfolded Stat. error (box)'\n",
    ")\n",
    "reco_handle, = plt.plot(bin_centers, Measured, 'o', label='Reco. signal')\n",
    "Model_smear = unfold['AddSmear'] @ Model\n",
    "true_handle, = plt.plot(bin_centers, Model_smear, 'o', label='$A_c \\\\times$ True signal')\n",
    "Fakedata_Model_smear = unfold['AddSmear'] @ nevts_fakedata_signal_truth*XSEC_UNIT\n",
    "fake_true_handle, = plt.plot(bin_centers, Fakedata_Model_smear, 'o', label='Fake Data')\n",
    "\n",
    "chi2_val = chi2(Unfold, Model_smear, UnfoldCov)\n",
    "chi2_val_fakedata = chi2(Unfold, Fakedata_Model_smear, UnfoldCov)\n",
    "# plt.text(0.95, 0.50, f\"$ \\\\chi^2 = $ {chi2_val:.2f}\", ha='right', va='center', \n",
    "#          transform=plt.gca().transAxes, fontsize=12)\n",
    "\n",
    "# Custom order for legend\n",
    "handles = [step_handle, bar_handle, reco_handle, true_handle, fake_true_handle]\n",
    "labels = [\n",
    "    'Unfolded',\n",
    "    'Unfolded error',\n",
    "    'Reco. signal',\n",
    "    '$A_c \\\\times$Nominal Truth ($\\\\chi^2 = {:.2f}/{}$)'.format(chi2_val, len(var_config.bins)-1),\n",
    "    '$A_c \\\\times$ MECx{} Truth ($\\\\chi^2 = {:.2f}/{}$)'.format(mec_scale, chi2_val_fakedata, len(var_config.bins)-1),\n",
    "]\n",
    "\n",
    "plt.legend(handles, labels, fontsize=12)\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[0])\n",
    "# plt.ylim(0., 5000.)\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-unfolded_event_rates.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_name = \"{}/{}-{}-add_smear\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_labels = [var_config.var_labels[2], var_config.var_labels[1]]\n",
    "plot_heatmap(unfold[\"AddSmear\"], \"$A_c$\", plot_labels=plot_labels,\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QE scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe_scale = 1.2\n",
    "weights_fake_data = np.ones(len(var_total_mc))\n",
    "weights_fake_data[mc_evt_df.genie_mode == 0] = qe_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "mc_stack, _, _ = plt.hist(var_per_nuint_categ_mc,\n",
    "                            bins=var_config.bins,\n",
    "                            weights=weights_per_categ,\n",
    "                            stacked=True,\n",
    "                            color=colors,\n",
    "                            label=mode_labels,\n",
    "                            edgecolor='none',\n",
    "                            linewidth=0,\n",
    "                            density=False,\n",
    "                            histtype='stepfilled')\n",
    "totmc, bin_edges = np.histogram(var_total_mc, bins=var_config.bins, weights=weights_total_mc * weights_fake_data)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# use MC as fake data for closure test\n",
    "fake_data = totmc\n",
    "fake_data_err = np.sqrt(totmc)\n",
    "plt.errorbar(bin_centers, fake_data, yerr=fake_data_err, fmt='o', color='black')  # error bars\n",
    "\n",
    "background_cv = mc_stack[-1] - mc_stack[0]\n",
    "# plt.hist(bin_centers, weights=fake_data - background_cv, bins=var_config.bins, histtype=\"step\", color=\"k\", label=\"Background\")\n",
    "\n",
    "accum_sum = [np.sum(data) for data in mc_stack]\n",
    "accum_sum = [0.] + accum_sum\n",
    "total_sum = accum_sum[-1]\n",
    "individual_sums = [accum_sum[i + 1] - accum_sum[i] for i in range(len(accum_sum) - 1)]\n",
    "fractions = [(count / total_sum) * 100 for count in individual_sums]\n",
    "legend_labels = [f\"{label} ({frac:.1f}%)\" for label, frac in zip(mode_labels[::-1], fractions[::-1])]\n",
    "legend_labels.append(\"Fake Data (QE x{})\".format(qe_scale))\n",
    "plt.legend(legend_labels, loc='upper left', fontsize=10, frameon=False, ncol=3, bbox_to_anchor=(0.05, 0.98))\n",
    "\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[1])\n",
    "plt.ylim(0., 1.3 * fake_data.max())\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-topology_breakdown.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect GENIE mode breakdown\n",
    "plt.figure(figsize=(8, 6))\n",
    "mc_stack, _, _ = plt.hist(var_per_genie_mode_mc,\n",
    "                            bins=var_config.bins,\n",
    "                            weights=weights_per_genie_mode,\n",
    "                            stacked=True,\n",
    "                            color=genie_mode_colors,\n",
    "                            label=genie_mode_labels,\n",
    "                            edgecolor='none',\n",
    "                            linewidth=0,\n",
    "                            density=False,\n",
    "                            histtype='stepfilled')\n",
    "\n",
    "totmc, bin_edges = np.histogram(var_total_mc, bins=var_config.bins, weights=weights_total_mc * weights_fake_data)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# use MC as fake data for closure test\n",
    "fake_data = totmc\n",
    "fake_data_err = np.sqrt(totmc)\n",
    "# plt.step(bin_edges[:-1], fake_data, where='post', label=\"Data\")  # line\n",
    "plt.errorbar(bin_centers, fake_data, yerr=fake_data_err, fmt='o', color='black')  # error bars\n",
    "\n",
    "accum_sum = [np.sum(data) for data in mc_stack]\n",
    "accum_sum = [0.] + accum_sum\n",
    "total_sum = accum_sum[-1]\n",
    "individual_sums = [accum_sum[i + 1] - accum_sum[i] for i in range(len(accum_sum) - 1)]\n",
    "fractions = [(count / total_sum) * 100 for count in individual_sums]\n",
    "legend_labels = [f\"{label} ({frac:.1f}%)\" for label, frac in zip(genie_mode_labels[::-1], fractions[::-1])]\n",
    "legend_labels.append(\"Fake Data (QE x{})\".format(qe_scale))\n",
    "plt.legend(legend_labels, loc='upper left', fontsize=10, frameon=False, ncol=3, bbox_to_anchor=(0.05, 0.98))\n",
    "\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[1])\n",
    "plt.ylim(0., 1.3 * fake_data.max())\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-genie_mode_breakdown.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake data test -- MC stat + xsec cov\n",
    "C_type = 2\n",
    "Norm_type = 0.5\n",
    "Measured = fake_data * XSEC_UNIT - background_cv * XSEC_UNIT\n",
    "Model = nevts_signal_truth * XSEC_UNIT\n",
    "\n",
    "# use MC stat and xsec cov\n",
    "Covariance_Frac = ret_genie[\"Covariance_Frac\"] + ret_mcstat[\"Covariance_Frac\"]\n",
    "\n",
    "Covariance = np.zeros_like(Covariance_Frac)\n",
    "for i in range(len(var_config.bins)-1):\n",
    "    for j in range(len(var_config.bins)-1):\n",
    "        Covariance[i, j] = Covariance_Frac[i, j] * (nevts_signal_sel_reco[i] * nevts_signal_sel_reco[j]) * XSEC_UNIT**2\n",
    "\n",
    "unfold = WienerSVD(Response, Model, Measured, Covariance, C_type, Norm_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true cross section for alt MC used asfake data\n",
    "var_fakedata_signal_truth = mc_nu_df[mc_nu_df.nuint_categ == 1][var_config.var_nu_col]\n",
    "var_fakedata_signal_truth = np.clip(var_fakedata_signal_truth, var_config.bins[0], var_config.bins[-1] - eps)\n",
    "weight_fakedata_signal_truth = np.ones(len(var_fakedata_signal_truth))\n",
    "nevts_fakedata_signal_truth, _, _ = plt.hist(var_fakedata_signal_truth, bins=var_config.bins, weights=weight_fakedata_signal_truth, histtype=\"step\", label=\"True Signal\")\n",
    "weight_fakedata_signal_truth[mc_nu_df[mc_nu_df.nuint_categ == 1].genie_mode == 0] = qe_scale\n",
    "nevts_fakedata_signal_truth, _, _ = plt.hist(var_fakedata_signal_truth, bins=var_config.bins, weights=weight_fakedata_signal_truth, histtype=\"step\", label=\"QE x{} True Signal\".format(qe_scale))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "Unfold = unfold['unfold']\n",
    "UnfoldCov = unfold['UnfoldCov']\n",
    "Unfold_uncert = np.sqrt(np.diag(UnfoldCov))\n",
    "\n",
    "step_handle, = plt.step(bin_edges, np.append(Unfold, Unfold[-1]), where='post', label='Unfolded', color='black')\n",
    "bar_handle = plt.bar(\n",
    "    bin_centers,\n",
    "    2*Unfold_uncert,\n",
    "    width=(bin_edges[1] - bin_edges[0]) * 1.,\n",
    "    bottom=Unfold - Unfold_uncert,\n",
    "    color='gray',\n",
    "    alpha=0.5,\n",
    "    linewidth=0,\n",
    "    label='Unfolded Stat. error (box)'\n",
    ")\n",
    "reco_handle, = plt.plot(bin_centers, Measured, 'o', label='Reco. signal')\n",
    "Model_smear = unfold['AddSmear'] @ Model\n",
    "true_handle, = plt.plot(bin_centers, Model_smear, 'o', label='$A_c \\\\times$ True signal')\n",
    "Fakedata_Model_smear = unfold['AddSmear'] @ nevts_fakedata_signal_truth*XSEC_UNIT\n",
    "fake_true_handle, = plt.plot(bin_centers, Fakedata_Model_smear, 'o', label='Fake Data')\n",
    "\n",
    "chi2_val = chi2(Unfold, Model_smear, UnfoldCov)\n",
    "chi2_val_fakedata = chi2(Unfold, Fakedata_Model_smear, UnfoldCov)\n",
    "# plt.text(0.95, 0.50, f\"$ \\\\chi^2 = $ {chi2_val:.2f}\", ha='right', va='center', \n",
    "#          transform=plt.gca().transAxes, fontsize=12)\n",
    "\n",
    "# Custom order for legend\n",
    "handles = [step_handle, bar_handle, reco_handle, true_handle, fake_true_handle]\n",
    "labels = [\n",
    "    'Unfolded',\n",
    "    'Unfolded error',\n",
    "    'Reco. signal',\n",
    "    '$A_c \\\\times$Nominal Truth ($\\\\chi^2 = {:.2f}/{}$)'.format(chi2_val, len(var_config.bins)-1),\n",
    "    '$A_c \\\\times$ QE x{} Truth ($\\\\chi^2 = {:.2f}/{}$)'.format(qe_scale, chi2_val_fakedata, len(var_config.bins)-1),\n",
    "]\n",
    "\n",
    "plt.legend(handles, labels, fontsize=12)\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[0])\n",
    "# plt.ylim(0., 5000.)\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-unfolded_event_rates.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_name = \"{}/{}-{}-add_smear\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_labels = [var_config.var_labels[2], var_config.var_labels[1]]\n",
    "plot_heatmap(unfold[\"AddSmear\"], \"$A_c$\", plot_labels=plot_labels,\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Np background scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Np_scale = 2\n",
    "weights_fake_data = np.ones(len(var_total_mc))\n",
    "weights_fake_data[mc_evt_df.nuint_categ == 2] = Np_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "mc_stack, _, _ = plt.hist(var_per_nuint_categ_mc,\n",
    "                            bins=var_config.bins,\n",
    "                            weights=weights_per_categ,\n",
    "                            stacked=True,\n",
    "                            color=colors,\n",
    "                            label=mode_labels,\n",
    "                            edgecolor='none',\n",
    "                            linewidth=0,\n",
    "                            density=False,\n",
    "                            histtype='stepfilled')\n",
    "totmc, bin_edges = np.histogram(var_total_mc, bins=var_config.bins, weights=weights_total_mc * weights_fake_data)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# use MC as fake data for closure test\n",
    "fake_data = totmc\n",
    "fake_data_err = np.sqrt(totmc)\n",
    "plt.errorbar(bin_centers, fake_data, yerr=fake_data_err, fmt='o', color='black')  # error bars\n",
    "\n",
    "background_cv = mc_stack[-1] - mc_stack[0]\n",
    "# plt.hist(bin_centers, weights=fake_data - background_cv, bins=var_config.bins, histtype=\"step\", color=\"k\", label=\"Background\")\n",
    "\n",
    "accum_sum = [np.sum(data) for data in mc_stack]\n",
    "accum_sum = [0.] + accum_sum\n",
    "total_sum = accum_sum[-1]\n",
    "individual_sums = [accum_sum[i + 1] - accum_sum[i] for i in range(len(accum_sum) - 1)]\n",
    "fractions = [(count / total_sum) * 100 for count in individual_sums]\n",
    "legend_labels = [f\"{label} ({frac:.1f}%)\" for label, frac in zip(mode_labels[::-1], fractions[::-1])]\n",
    "legend_labels.append(\"Fake Data (Np x{})\".format(Np_scale))\n",
    "plt.legend(legend_labels, loc='upper left', fontsize=10, frameon=False, ncol=3, bbox_to_anchor=(0.05, 0.98))\n",
    "\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[1])\n",
    "plt.ylim(0., 1.3 * fake_data.max())\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-topology_breakdown.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect GENIE mode breakdown\n",
    "plt.figure(figsize=(8, 6))\n",
    "mc_stack, _, _ = plt.hist(var_per_genie_mode_mc,\n",
    "                            bins=var_config.bins,\n",
    "                            weights=weights_per_genie_mode,\n",
    "                            stacked=True,\n",
    "                            color=genie_mode_colors,\n",
    "                            label=genie_mode_labels,\n",
    "                            edgecolor='none',\n",
    "                            linewidth=0,\n",
    "                            density=False,\n",
    "                            histtype='stepfilled')\n",
    "\n",
    "totmc, bin_edges = np.histogram(var_total_mc, bins=var_config.bins, weights=weights_total_mc * weights_fake_data)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# use MC as fake data for closure test\n",
    "fake_data = totmc\n",
    "fake_data_err = np.sqrt(totmc)\n",
    "# plt.step(bin_edges[:-1], fake_data, where='post', label=\"Data\")  # line\n",
    "plt.errorbar(bin_centers, fake_data, yerr=fake_data_err, fmt='o', color='black')  # error bars\n",
    "\n",
    "accum_sum = [np.sum(data) for data in mc_stack]\n",
    "accum_sum = [0.] + accum_sum\n",
    "total_sum = accum_sum[-1]\n",
    "individual_sums = [accum_sum[i + 1] - accum_sum[i] for i in range(len(accum_sum) - 1)]\n",
    "fractions = [(count / total_sum) * 100 for count in individual_sums]\n",
    "legend_labels = [f\"{label} ({frac:.1f}%)\" for label, frac in zip(genie_mode_labels[::-1], fractions[::-1])]\n",
    "legend_labels.append(\"Fake Data (Np x{})\".format(Np_scale))\n",
    "plt.legend(legend_labels, loc='upper left', fontsize=10, frameon=False, ncol=3, bbox_to_anchor=(0.05, 0.98))\n",
    "\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[1])\n",
    "plt.ylim(0., 1.3 * fake_data.max())\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-genie_mode_breakdown.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake data test -- MC stat + xsec cov\n",
    "C_type = 2\n",
    "Norm_type = 0.5\n",
    "Measured = fake_data * XSEC_UNIT - background_cv * XSEC_UNIT\n",
    "Model = nevts_signal_truth * XSEC_UNIT\n",
    "\n",
    "# use MC stat and xsec cov\n",
    "Covariance_Frac = ret_genie[\"Covariance_Frac\"] + ret_mcstat[\"Covariance_Frac\"]\n",
    "\n",
    "Covariance = np.zeros_like(Covariance_Frac)\n",
    "for i in range(len(var_config.bins)-1):\n",
    "    for j in range(len(var_config.bins)-1):\n",
    "        Covariance[i, j] = Covariance_Frac[i, j] * (nevts_signal_sel_reco[i] * nevts_signal_sel_reco[j]) * XSEC_UNIT**2\n",
    "\n",
    "unfold = WienerSVD(Response, Model, Measured, Covariance, C_type, Norm_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true cross section for alt MC used asfake data\n",
    "var_fakedata_signal_truth = mc_nu_df[mc_nu_df.nuint_categ == 1][var_config.var_nu_col]\n",
    "var_fakedata_signal_truth = np.clip(var_fakedata_signal_truth, var_config.bins[0], var_config.bins[-1] - eps)\n",
    "weight_fakedata_signal_truth = np.ones(len(var_fakedata_signal_truth))\n",
    "nevts_fakedata_signal_truth, _, _ = plt.hist(var_fakedata_signal_truth, bins=var_config.bins, weights=weight_fakedata_signal_truth, histtype=\"step\", label=\"True Signal\")\n",
    "weight_fakedata_signal_truth[mc_nu_df[mc_nu_df.nuint_categ == 1].nuint_categ == 2] = Np_scale\n",
    "nevts_fakedata_signal_truth, _, _ = plt.hist(var_fakedata_signal_truth, bins=var_config.bins, weights=weight_fakedata_signal_truth, histtype=\"step\", label=\"Np x{} True Signal\".format(Np_scale))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "Unfold = unfold['unfold']\n",
    "UnfoldCov = unfold['UnfoldCov']\n",
    "Unfold_uncert = np.sqrt(np.diag(UnfoldCov))\n",
    "\n",
    "step_handle, = plt.step(bin_edges, np.append(Unfold, Unfold[-1]), where='post', label='Unfolded', color='black')\n",
    "bar_handle = plt.bar(\n",
    "    bin_centers,\n",
    "    2*Unfold_uncert,\n",
    "    width=(bin_edges[1] - bin_edges[0]) * 1.,\n",
    "    bottom=Unfold - Unfold_uncert,\n",
    "    color='gray',\n",
    "    alpha=0.5,\n",
    "    linewidth=0,\n",
    "    label='Unfolded Stat. error (box)'\n",
    ")\n",
    "reco_handle, = plt.plot(bin_centers, Measured, 'o', label='Reco. signal')\n",
    "Model_smear = unfold['AddSmear'] @ Model\n",
    "true_handle, = plt.plot(bin_centers, Model_smear, 'o', label='$A_c \\\\times$ True signal')\n",
    "Fakedata_Model_smear = unfold['AddSmear'] @ nevts_fakedata_signal_truth*XSEC_UNIT\n",
    "fake_true_handle, = plt.plot(bin_centers, Fakedata_Model_smear, 'o', label='Fake Data')\n",
    "\n",
    "chi2_val = chi2(Unfold, Model_smear, UnfoldCov)\n",
    "chi2_val_fakedata = chi2(Unfold, Fakedata_Model_smear, UnfoldCov)\n",
    "# plt.text(0.95, 0.50, f\"$ \\\\chi^2 = $ {chi2_val:.2f}\", ha='right', va='center', \n",
    "#          transform=plt.gca().transAxes, fontsize=12)\n",
    "\n",
    "# Custom order for legend\n",
    "handles = [step_handle, bar_handle, reco_handle, true_handle, fake_true_handle]\n",
    "labels = [\n",
    "    'Unfolded',\n",
    "    'Unfolded error',\n",
    "    'Reco. signal',\n",
    "    '$A_c \\\\times$Nominal Truth ($\\\\chi^2 = {:.2f}/{}$)'.format(chi2_val, len(var_config.bins)-1),\n",
    "    '$A_c \\\\times$ Np x{} Truth ($\\\\chi^2 = {:.2f}/{}$)'.format(Np_scale, chi2_val_fakedata, len(var_config.bins)-1),\n",
    "]\n",
    "\n",
    "plt.legend(handles, labels, fontsize=12)\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[0])\n",
    "# plt.ylim(0., 5000.)\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-unfolded_event_rates.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_name = \"{}/{}-{}-add_smear\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_labels = [var_config.var_labels[2], var_config.var_labels[1]]\n",
    "plot_heatmap(unfold[\"AddSmear\"], \"$A_c$\", plot_labels=plot_labels,\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_scale = 1.2\n",
    "weights_fake_data = np.ones(len(var_total_mc))\n",
    "weights_fake_data[mc_evt_df.nuint_categ == 1] = sig_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "mc_stack, _, _ = plt.hist(var_per_nuint_categ_mc,\n",
    "                            bins=var_config.bins,\n",
    "                            weights=weights_per_categ,\n",
    "                            stacked=True,\n",
    "                            color=colors,\n",
    "                            label=mode_labels,\n",
    "                            edgecolor='none',\n",
    "                            linewidth=0,\n",
    "                            density=False,\n",
    "                            histtype='stepfilled')\n",
    "totmc, bin_edges = np.histogram(var_total_mc, bins=var_config.bins, weights=weights_total_mc * weights_fake_data)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# use MC as fake data for closure test\n",
    "fake_data = totmc\n",
    "fake_data_err = np.sqrt(totmc)\n",
    "plt.errorbar(bin_centers, fake_data, yerr=fake_data_err, fmt='o', color='black')  # error bars\n",
    "\n",
    "background_cv = mc_stack[-1] - mc_stack[0]\n",
    "# plt.hist(bin_centers, weights=fake_data - background_cv, bins=var_config.bins, histtype=\"step\", color=\"k\", label=\"Background\")\n",
    "\n",
    "accum_sum = [np.sum(data) for data in mc_stack]\n",
    "accum_sum = [0.] + accum_sum\n",
    "total_sum = accum_sum[-1]\n",
    "individual_sums = [accum_sum[i + 1] - accum_sum[i] for i in range(len(accum_sum) - 1)]\n",
    "fractions = [(count / total_sum) * 100 for count in individual_sums]\n",
    "legend_labels = [f\"{label} ({frac:.1f}%)\" for label, frac in zip(mode_labels[::-1], fractions[::-1])]\n",
    "legend_labels.append(\"Fake Data (Np x{})\".format(sig_scale))\n",
    "plt.legend(legend_labels, loc='upper left', fontsize=10, frameon=False, ncol=3, bbox_to_anchor=(0.05, 0.98))\n",
    "\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[1])\n",
    "plt.ylim(0., 1.3 * fake_data.max())\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-topology_breakdown.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect GENIE mode breakdown\n",
    "plt.figure(figsize=(8, 6))\n",
    "mc_stack, _, _ = plt.hist(var_per_genie_mode_mc,\n",
    "                            bins=var_config.bins,\n",
    "                            weights=weights_per_genie_mode,\n",
    "                            stacked=True,\n",
    "                            color=genie_mode_colors,\n",
    "                            label=genie_mode_labels,\n",
    "                            edgecolor='none',\n",
    "                            linewidth=0,\n",
    "                            density=False,\n",
    "                            histtype='stepfilled')\n",
    "\n",
    "totmc, bin_edges = np.histogram(var_total_mc, bins=var_config.bins, weights=weights_total_mc * weights_fake_data)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# use MC as fake data for closure test\n",
    "fake_data = totmc\n",
    "fake_data_err = np.sqrt(totmc)\n",
    "# plt.step(bin_edges[:-1], fake_data, where='post', label=\"Data\")  # line\n",
    "plt.errorbar(bin_centers, fake_data, yerr=fake_data_err, fmt='o', color='black')  # error bars\n",
    "\n",
    "accum_sum = [np.sum(data) for data in mc_stack]\n",
    "accum_sum = [0.] + accum_sum\n",
    "total_sum = accum_sum[-1]\n",
    "individual_sums = [accum_sum[i + 1] - accum_sum[i] for i in range(len(accum_sum) - 1)]\n",
    "fractions = [(count / total_sum) * 100 for count in individual_sums]\n",
    "legend_labels = [f\"{label} ({frac:.1f}%)\" for label, frac in zip(genie_mode_labels[::-1], fractions[::-1])]\n",
    "legend_labels.append(\"Fake Data (Np x{})\".format(sig_scale))\n",
    "plt.legend(legend_labels, loc='upper left', fontsize=10, frameon=False, ncol=3, bbox_to_anchor=(0.05, 0.98))\n",
    "\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[1])\n",
    "plt.ylim(0., 1.3 * fake_data.max())\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-genie_mode_breakdown.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake data test -- MC stat + xsec cov\n",
    "C_type = 2\n",
    "Norm_type = 0.5\n",
    "Measured = fake_data * XSEC_UNIT - background_cv * XSEC_UNIT\n",
    "Model = nevts_signal_truth * XSEC_UNIT\n",
    "\n",
    "# use MC stat and xsec cov\n",
    "Covariance_Frac = ret_genie[\"Covariance_Frac\"] + ret_mcstat[\"Covariance_Frac\"]\n",
    "\n",
    "Covariance = np.zeros_like(Covariance_Frac)\n",
    "for i in range(len(var_config.bins)-1):\n",
    "    for j in range(len(var_config.bins)-1):\n",
    "        Covariance[i, j] = Covariance_Frac[i, j] * (nevts_signal_sel_reco[i] * nevts_signal_sel_reco[j]) * XSEC_UNIT**2\n",
    "\n",
    "unfold = WienerSVD(Response, Model, Measured, Covariance, C_type, Norm_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true cross section for alt MC used asfake data\n",
    "var_fakedata_signal_truth = mc_nu_df[mc_nu_df.nuint_categ == 1][var_config.var_nu_col]\n",
    "var_fakedata_signal_truth = np.clip(var_fakedata_signal_truth, var_config.bins[0], var_config.bins[-1] - eps)\n",
    "weight_fakedata_signal_truth = np.ones(len(var_fakedata_signal_truth))\n",
    "nevts_fakedata_signal_truth, _, _ = plt.hist(var_fakedata_signal_truth, bins=var_config.bins, weights=weight_fakedata_signal_truth, histtype=\"step\", label=\"True Signal\")\n",
    "weight_fakedata_signal_truth[mc_nu_df[mc_nu_df.nuint_categ == 1].nuint_categ == 1] = sig_scale\n",
    "nevts_fakedata_signal_truth, _, _ = plt.hist(var_fakedata_signal_truth, bins=var_config.bins, weights=weight_fakedata_signal_truth, histtype=\"step\", label=\"MEC x{} True Signal\".format(mec_scale))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "Unfold = unfold['unfold']\n",
    "UnfoldCov = unfold['UnfoldCov']\n",
    "Unfold_uncert = np.sqrt(np.diag(UnfoldCov))\n",
    "\n",
    "step_handle, = plt.step(bin_edges, np.append(Unfold, Unfold[-1]), where='post', label='Unfolded', color='black')\n",
    "bar_handle = plt.bar(\n",
    "    bin_centers,\n",
    "    2*Unfold_uncert,\n",
    "    width=(bin_edges[1] - bin_edges[0]) * 1.,\n",
    "    bottom=Unfold - Unfold_uncert,\n",
    "    color='gray',\n",
    "    alpha=0.5,\n",
    "    linewidth=0,\n",
    "    label='Unfolded Stat. error (box)'\n",
    ")\n",
    "reco_handle, = plt.plot(bin_centers, Measured, 'o', label='Reco. signal')\n",
    "Model_smear = unfold['AddSmear'] @ Model\n",
    "true_handle, = plt.plot(bin_centers, Model_smear, 'o', label='$A_c \\\\times$ True signal')\n",
    "Fakedata_Model_smear = unfold['AddSmear'] @ nevts_fakedata_signal_truth*XSEC_UNIT\n",
    "fake_true_handle, = plt.plot(bin_centers, Fakedata_Model_smear, 'o', label='Fake Data')\n",
    "\n",
    "chi2_val = chi2(Unfold, Model_smear, UnfoldCov)\n",
    "chi2_val_fakedata = chi2(Unfold, Fakedata_Model_smear, UnfoldCov)\n",
    "# plt.text(0.95, 0.50, f\"$ \\\\chi^2 = $ {chi2_val:.2f}\", ha='right', va='center', \n",
    "#          transform=plt.gca().transAxes, fontsize=12)\n",
    "\n",
    "# Custom order for legend\n",
    "handles = [step_handle, bar_handle, reco_handle, true_handle, fake_true_handle]\n",
    "labels = [\n",
    "    'Unfolded',\n",
    "    'Unfolded error',\n",
    "    'Reco. signal',\n",
    "    '$A_c \\\\times$Nominal Truth ($\\\\chi^2 = {:.2f}/{}$)'.format(chi2_val, len(var_config.bins)-1),\n",
    "    '$A_c \\\\times$ Signal x{} Truth ($\\\\chi^2 = {:.2f}/{}$)'.format(sig_scale, chi2_val_fakedata, len(var_config.bins)-1),\n",
    "]\n",
    "\n",
    "plt.legend(handles, labels, fontsize=12)\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[0])\n",
    "# plt.ylim(0., 5000.)\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-unfolded_event_rates.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_name = \"{}/{}-{}-add_smear\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_labels = [var_config.var_labels[2], var_config.var_labels[1]]\n",
    "plot_heatmap(unfold[\"AddSmear\"], \"$A_c$\", plot_labels=plot_labels,\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_py39_cafpyana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
